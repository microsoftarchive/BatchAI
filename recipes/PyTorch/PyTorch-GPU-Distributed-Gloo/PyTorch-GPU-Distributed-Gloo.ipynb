{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Distributed GPU Using Gloo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This example demonstrates how to run distributed GPU training for PyTorch using Gloo backend in Batch AI\n",
    "\n",
    "## Details\n",
    "\n",
    "- The Gloo backend will be implemented using Batch AI shared job temporary directory which is visible for all GPU nodes in the job\n",
    "- Will use Batch AI generated AZ_BATCHAI_PYTORCH_INIT_METHOD for shared file-system initialization.\n",
    "- Will use Batch AI generated AZ_BATCHAI_TASK_INDEX as rank of each worker process\n",
    "- Standard output of the job will be stored on Azure File Share.\n",
    "- PyTorch training script [mnist_trainer.py](./mnist_trainer.py) is attached, which trains a CNN for MNIST dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "### Install Dependencies and Create Configuration file.\n",
    "Follow [instructions](/recipes) to install all dependencies and create configuration file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Configuration and Create Batch AI client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "bfa11f00-8866-4051-bbfe-a9646e004910"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from azure.storage.file import FileService, FilePermissions\n",
    "import azure.mgmt.batchai.models as models\n",
    "\n",
    "# The BatchAI/utilities folder contains helper functions used by different notebooks\n",
    "sys.path.append('../../../')\n",
    "import utilities as utils\n",
    "\n",
    "cfg = utils.config.Configuration('..\\..\\configuration.json')\n",
    "client = utils.config.create_batchai_client(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Resoruce Group and Batch AI workspace if not existsï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "utils.config.create_resource_group(cfg)\n",
    "_ = client.workspaces.create(cfg.resource_group, cfg.workspace, cfg.location).result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prepare Training Dataset and Script in Azure Storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Azure File Share\n",
    "\n",
    "For this example we will create a new File Share with name `batchaisample` under your storage account. This will be used to share the *training script file* and *output file*.\n",
    "\n",
    "**Note** You don't need to create new file share for every cluster. We are doing this in this sample to simplify resource management for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "azure_file_share_name = 'batchaisample'\n",
    "service = FileService(cfg.storage_account_name, cfg.storage_account_key)\n",
    "service.create_share(azure_file_share_name, fail_on_exist=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy Sample Script \n",
    "For each job we will create a folder containing a copy of script [mnist_trainer.py](./mnist_trainer.py). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pyTorchSamples = \"PyTorchSamples\"\n",
    "service = FileService(cfg.storage_account_name, cfg.storage_account_key)\n",
    "service.create_directory(\n",
    "    azure_file_share_name, pyTorchSamples, fail_on_exist=False)\n",
    "service.create_file_from_path(\n",
    "    azure_file_share_name, pyTorchSamples, 'mnist_trainer.py', 'mnist_trainer.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create Azure Batch AI Compute Cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Compute Cluster\n",
    "- For this example we will use a gpu cluster of 2 `STANDARD_NC6` nodes. You can increase the number of nodes by changing `nodes_count` variable;\n",
    "- We will call the cluster `nc6`;\n",
    "\n",
    "So, the cluster will have the following parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nodes_count = 2\n",
    "cluster_name = 'nc6'\n",
    "\n",
    "parameters = models.ClusterCreateParameters(\n",
    "    location=cfg.location,\n",
    "    vm_size='STANDARD_NC6',\n",
    "    scale_settings=models.ScaleSettings(\n",
    "        manual=models.ManualScaleSettings(target_node_count=nodes_count)\n",
    "    ),\n",
    "    user_account_settings=models.UserAccountSettings(\n",
    "        admin_user_name=cfg.admin,\n",
    "        admin_user_password=cfg.admin_password or None,\n",
    "        admin_user_ssh_public_key=cfg.admin_ssh_key or None,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Compute Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_ = client.clusters.create(cfg.resource_group, cfg.workspace, cluster_name, parameters).result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monitor Cluster Creation\n",
    "\n",
    "Get the just created cluster. The `utilities` module contains a helper function to print out all kind of nodes count in the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cluster = client.clusters.get(cfg.resource_group, cfg.workspace, cluster_name)\n",
    "utils.cluster.print_cluster_status(cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Run Azure Batch AI Training Job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Job\n",
    "- The job will use `pytorch/pytorch:0.4_cuda9_cudnn7` container.\n",
    "- Will use configured previously input and output directories;\n",
    "- Will mount file share at folder with name `afs`. Full path of this folder on a computer node will be `AZ_BATCHAI_JOB_MOUNT_ROOT/afs`;\n",
    "- Will run modified `mnist_trainer.py` from SCRIPT input directory;\n",
    "- Will output standard output and error streams to file share;\n",
    "- Will use `'Gloo'` as PyTorch distribution backend, and use Batch AI generated `AZ_BATCHAI_PYTORCH_INIT_METHOD` for shared file-system initialization.\n",
    "- Will use Batch AI generated `AZ_BATCHAI_TASK_INDEX` as rank of each worker process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "azure_file_share = 'afs'\n",
    "parameters = models.JobCreateParameters(\n",
    "     location=cfg.location,\n",
    "     cluster=models.ResourceId(id=cluster.id),\n",
    "     node_count=2,\n",
    "     std_out_err_path_prefix=\"$AZ_BATCHAI_JOB_MOUNT_ROOT/{0}\".format(azure_file_share),\n",
    "     mount_volumes=models.MountVolumes(\n",
    "            azure_file_shares=[\n",
    "                models.AzureFileShareReference(\n",
    "                    account_name=cfg.storage_account_name,\n",
    "                    credentials=models.AzureStorageCredentialsInfo(\n",
    "                        account_key=cfg.storage_account_key),\n",
    "                    azure_file_url='https://{0}.file.core.windows.net/{1}'.format(\n",
    "                        cfg.storage_account_name, azure_file_share_name),\n",
    "                    relative_mount_path=azure_file_share)\n",
    "            ]\n",
    "        ), \n",
    "     container_settings=models.ContainerSettings(\n",
    "          image_source_registry=models.ImageSourceRegistry(image='pytorch/pytorch:0.4_cuda9_cudnn7')),\n",
    "     py_torch_settings = models.PyTorchSettings(\n",
    "         python_script_file_path='$AZ_BATCHAI_JOB_MOUNT_ROOT/{0}/{1}/mnist_trainer.py'.format(azure_file_share, pyTorchSamples),\n",
    "         command_line_args='--epochs 10 --world-size 2 --dist-backend gloo --dist-url $AZ_BATCHAI_PYTORCH_INIT_METHOD --rank $AZ_BATCHAI_TASK_INDEX',\n",
    "         communication_backend='gloo'))\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a training Job and wait for Job completion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "experiment_name = 'pytorch_experiment'\n",
    "experiment = client.experiments.create(cfg.resource_group, cfg.workspace, experiment_name).result()\n",
    "job_name = datetime.utcnow().strftime('pytorch_%m_%d_%Y_%H%M%S')\n",
    "job = client.jobs.create(cfg.resource_group, cfg.workspace, experiment_name, job_name, parameters).result()\n",
    "print('Created Job {0} in Experiment {1}'.format(job.name, experiment.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wait for Job to Finish\n",
    "The job will start running when the cluster will have enought idle nodes. The following code waits for job to start running printing the cluster state. During job run, the code prints current content of stdout.txt.\n",
    "\n",
    "**Note** Execution may take several minutes to complete. Due to a known bug in PyTorch Gloo backend, the job may fail with the following error as [reported](https://github.com/pytorch/pytorch/issues/2530):\n",
    "```\n",
    "terminate called after throwing an instance of 'gloo::EnforceNotMet'\n",
    "  what():  [enforce fail at /pytorch/torch/lib/gloo/gloo/cuda.cu:249] error == cudaSuccess. 29 vs 0. Error at: /pytorch/torch/lib/gloo/gloo/cuda.cu:249: driver shutting down\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "utils.job.wait_for_job_completion(client, cfg.resource_group, cfg.workspace, \n",
    "                                  experiment_name, job_name, cluster_name,'stdouterr', 'stdout-0.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### List stdout.txt and stderr.txt files for the Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "files = client.jobs.list_output_files(cfg.resource_group, cfg.workspace, experiment_name, job_name,\n",
    "                                      models.JobsListOutputFilesOptions(outputdirectoryid='stdouterr')) \n",
    "for f in list(files):\n",
    "    print(f.name, f.download_url or 'directory')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Clean Up (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete the Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_ = client.jobs.delete(cfg.resource_group, cfg.workspace, experiment_name, job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete the Cluster\n",
    "When you are finished with the sample and don't want to submit any more jobs you can delete the cluster using the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_ = client.clusters.delete(cfg.resource_group, cfg.workspace, cluster_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Delete File Share\n",
    "When you are finished with the sample and don't want to submit any more jobs you can delete the file share completely with all files using the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "service = FileService(cfg.storage_account_name, cfg.storage_account_key)\n",
    "service.delete_share(azure_file_share_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
